pipeline {
    agent any

    environment {
        // Путь до Spark, если установлено в переменной SPARK_HOME на агенте
        SPARK_HOME = "${env.SPARK_HOME ?: '/opt/homebrew/bin'}"
        JDBC_JAR = 'clickhouse-jdbc-all.jar'
    }

    stages {
        stage('Start Services') {
            steps {
                sh 'docker-compose up -d'
                sh 'sleep 15'
            }
        }

        stage('Init MySQL') {
            steps {
                // Исправлен путь к контейнеру и к файлу
                sh '''
                    if docker ps --format '{{.Names}}' | grep -q "project-mysql-1"; then
                      docker exec project-mysql-1 sh -c 'mysql -uroot -proot bank < /sql/init_mysql.sql'
                    else
                      echo "MySQL container not found, skipping init"
                    fi
                '''
            }
        }

        stage('Register Debezium Connector') {
            steps {
                sh '''
                    echo "Registering Debezium Connector..."
                    curl -i -X POST http://localhost:8083/connectors \\
                        -H "Content-Type: application/json" \\
                        --data-binary @debezium-connector.json || true
                '''
            }
        }

        stage('Prepare JARs') {
            steps {
                sh '''
                    # Скачиваем JDBC-all, если его нет
                    if [ ! -f "${JDBC_JAR}" ]; then
                      wget https://repo1.maven.org/maven2/com/clickhouse/clickhouse-jdbc/0.6.0-patch20/clickhouse-jdbc-0.6.0-patch20-all.jar \
                        -O ${JDBC_JAR}
                    fi
                '''
            }
        }

        stage('Create ClickHouse Views') {
            steps {
                sh '''
                    if docker ps --format '{{.Names}}' | grep -q "clickhouse-server"; then
                      docker exec clickhouse-server clickhouse-client \
                        --user=custom_user --password=0000 \
                        --query="CREATE DATABASE IF NOT EXISTS default;"
                    else
                      echo "ClickHouse container not found, skipping DB creation"
                    fi
                '''
            }
        }

        stage('Run Spark Job') {
            steps {
                // Используем SPARK_HOME из env
                sh '''
                    echo "Running Spark job..."
                    ${SPARK_HOME}/spark-submit \
                      --jars ${JDBC_JAR} \
                      --master local[1] \
                      etl/kafka_to_clickhouse.py
                '''
            }
        }
    }

    post {
        always {
            // Останавливаем и очищаем контейнеры, удаляем volume
            sh '''
                docker-compose down -v
            '''
        }
    }
}
